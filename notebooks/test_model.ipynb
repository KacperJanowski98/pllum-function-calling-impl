{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Fine-tuned PLLuM Model for Function Calling\n",
    "\n",
    "This notebook demonstrates how to load and use the fine-tuned PLLuM model for function calling. After completing the fine-tuning process in `fine_tuning.ipynb`, you can use this notebook to test the model with your own queries and tool definitions.\n",
    "\n",
    "The model has been fine-tuned to generate function calls in response to user queries, supporting both Polish and English languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import our fine-tuning utilities\n",
    "from src.fine_tuning import (\n",
    "    load_fine_tuned_model,\n",
    "    generate_function_call,\n",
    ")\n",
    "from src.auth import login  # For Hugging Face authentication\n",
    "\n",
    "# Load environment variables and authenticate with Hugging Face\n",
    "load_dotenv()\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Available Models\n",
    "\n",
    "Let's check for available fine-tuned models in the models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Locate fine-tuned models\n",
    "MODELS_DIR = \"../models\"\n",
    "model_dirs = [d for d in glob.glob(f\"{MODELS_DIR}/pllum-function-calling-*\") if os.path.isdir(d)]\n",
    "\n",
    "print(\"Available fine-tuned models:\")\n",
    "for i, model_dir in enumerate(model_dirs):\n",
    "    # Try to load the training summary if available\n",
    "    summary_path = os.path.join(model_dir, \"training_summary.json\")\n",
    "    if os.path.exists(summary_path):\n",
    "        with open(summary_path, 'r', encoding='utf-8') as f:\n",
    "            summary = json.load(f)\n",
    "        print(f\"{i+1}. {os.path.basename(model_dir)} - Trained on: {summary.get('training_date', 'Unknown')}\")\n",
    "    else:\n",
    "        print(f\"{i+1}. {os.path.basename(model_dir)}\")\n",
    "\n",
    "if not model_dirs:\n",
    "    print(\"No fine-tuned models found in the models directory.\")\n",
    "    print(\"Please run the fine_tuning.ipynb notebook first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Select and load a model\n",
    "if model_dirs:\n",
    "    # Choose the most recent model (or you can select a specific one)\n",
    "    MODEL_PATH = model_dirs[-1]  # Most recent model\n",
    "    print(f\"Loading model from: {MODEL_PATH}\")\n",
    "    \n",
    "    model, tokenizer = load_fine_tuned_model(MODEL_PATH)\n",
    "    print(\"Model loaded successfully.\")\n",
    "else:\n",
    "    # No models found, alert the user\n",
    "    print(\"No fine-tuned models available.\")\n",
    "    MODEL_PATH = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Dataset Examples\n",
    "\n",
    "First, let's load the dataset and test with some examples from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "DATASET_PATH = \"../data/translated_dataset.json\"\n",
    "\n",
    "if os.path.exists(DATASET_PATH) and MODEL_PATH:\n",
    "    with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "        dataset = json.load(f)\n",
    "    print(f\"Dataset loaded with {len(dataset)} examples.\")\n",
    "    \n",
    "    # Test with a random example from the dataset\n",
    "    import random\n",
    "    example_idx = random.randint(0, len(dataset) - 1)\n",
    "    example = dataset[example_idx]\n",
    "    \n",
    "    print(f\"\\nTesting with example {example_idx}:\")\n",
    "    print(f\"Query: {example['query']}\")\n",
    "    print(\"\\nAvailable tools:\")\n",
    "    for i, tool in enumerate(example['tools']):\n",
    "        print(f\"{i+1}. {tool['name']}: {tool['description']}\")\n",
    "    \n",
    "    print(\"\\nExpected answer:\")\n",
    "    print(json.dumps(example['answers'], indent=2, ensure_ascii=False))\n",
    "    \n",
    "    print(\"\\nGenerating function call...\")\n",
    "    generated = generate_function_call(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        query=example['query'],\n",
    "        tools=example['tools'],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nGenerated answer:\")\n",
    "    print(json.dumps(generated, indent=2, ensure_ascii=False))\n",
    "elif not MODEL_PATH:\n",
    "    print(\"Please load a model first.\")\n",
    "else:\n",
    "    print(f\"Dataset not found at {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Custom Examples\n",
    "\n",
    "Now let's test with our own custom examples to see how the model generalizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define some custom tools for testing\n",
    "weather_tools = [\n",
    "    {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather for a location\",\n",
    "        \"parameters\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state or country (e.g., 'Warsaw, Poland')\",\n",
    "                \"required\": True\n",
    "            },\n",
    "            \"unit\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The unit of temperature: 'celsius' or 'fahrenheit'\",\n",
    "                \"required\": False\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_forecast\",\n",
    "        \"description\": \"Get the weather forecast for the next N days\",\n",
    "        \"parameters\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state or country\",\n",
    "                \"required\": True\n",
    "            },\n",
    "            \"days\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"Number of days for the forecast (1-10)\",\n",
    "                \"required\": True\n",
    "            },\n",
    "            \"unit\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The unit of temperature: 'celsius' or 'fahrenheit'\",\n",
    "                \"required\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "calculator_tools = [\n",
    "    {\n",
    "        \"name\": \"calculator\",\n",
    "        \"description\": \"Perform basic arithmetic calculations\",\n",
    "        \"parameters\": {\n",
    "            \"expression\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The mathematical expression to evaluate\",\n",
    "                \"required\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "calendar_tools = [\n",
    "    {\n",
    "        \"name\": \"create_calendar_event\",\n",
    "        \"description\": \"Create a new calendar event\",\n",
    "        \"parameters\": {\n",
    "            \"title\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Title of the event\",\n",
    "                \"required\": True\n",
    "            },\n",
    "            \"start_time\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Start time in ISO format\",\n",
    "                \"required\": True\n",
    "            },\n",
    "            \"end_time\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"End time in ISO format\",\n",
    "                \"required\": True\n",
    "            },\n",
    "            \"description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Description of the event\",\n",
    "                \"required\": False\n",
    "            },\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Location of the event\",\n",
    "                \"required\": False\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define a function to test with custom queries\n",
    "def test_custom_query(query, tools, temperature=0.1):\n",
    "    if not MODEL_PATH:\n",
    "        print(\"Please load a model first.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"\\nAvailable tools:\")\n",
    "    for i, tool in enumerate(tools):\n",
    "        print(f\"{i+1}. {tool['name']}: {tool['description']}\")\n",
    "    \n",
    "    print(\"\\nGenerating function call...\")\n",
    "    generated = generate_function_call(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        query=query,\n",
    "        tools=tools,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    \n",
    "    print(\"\\nGenerated answer:\")\n",
    "    print(json.dumps(generated, indent=2, ensure_ascii=False))\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test with weather tools (English query)\n",
    "english_weather_query = \"What's the weather like in Warsaw today?\"\n",
    "test_custom_query(english_weather_query, weather_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test with weather tools (Polish query)\n",
    "polish_weather_query = \"Jaka jest dzisiaj pogoda w Warszawie?\"\n",
    "test_custom_query(polish_weather_query, weather_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test with calculator tools (English query)\n",
    "english_calc_query = \"What is 145 multiplied by 37?\"\n",
    "test_custom_query(english_calc_query, calculator_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test with calculator tools (Polish query)\n",
    "polish_calc_query = \"Ile to jest 145 razy 37?\"\n",
    "test_custom_query(polish_calc_query, calculator_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test with calendar tools (English query)\n",
    "english_calendar_query = \"Schedule a meeting with John tomorrow at 3pm for 1 hour to discuss the project\"\n",
    "test_custom_query(english_calendar_query, calendar_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test with calendar tools (Polish query)\n",
    "polish_calendar_query = \"Zaplanuj spotkanie z Janem jutro o 15:00 na godzinę, aby omówić projekt\"\n",
    "test_custom_query(polish_calendar_query, calendar_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Combination of Tools\n",
    "\n",
    "Let's see how the model handles scenarios with multiple tool options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Combine multiple tools\n",
    "combined_tools = weather_tools + calculator_tools + calendar_tools\n",
    "\n",
    "# Test with combined tools (English)\n",
    "combined_query_english = \"Calculate 25% of 840\"\n",
    "test_custom_query(combined_query_english, combined_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test with combined tools (Polish)\n",
    "combined_query_polish = \"Dodaj do kalendarza spotkanie z zespołem na jutro od 10:00 do 11:30 w sali konferencyjnej\"\n",
    "test_custom_query(combined_query_polish, combined_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Performance\n",
    "\n",
    "Let's qualitatively evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to rate model responses\n",
    "def rate_response(generated, expected=None):\n",
    "    print(\"Please rate the model's response (1-5):\")\n",
    "    print(\"1: Completely incorrect\")\n",
    "    print(\"2: Partially incorrect\")\n",
    "    print(\"3: Somewhat correct but with errors\")\n",
    "    print(\"4: Mostly correct with minor issues\")\n",
    "    print(\"5: Perfectly correct\")\n",
    "    \n",
    "    if expected:\n",
    "        print(\"\\nExpected response:\")\n",
    "        print(json.dumps(expected, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    print(\"\\nGenerated response:\")\n",
    "    print(json.dumps(generated, indent=2, ensure_ascii=False))\n",
    "    \n",
    "    rating = input(\"Your rating (1-5): \")\n",
    "    comment = input(\"Comments (optional): \")\n",
    "    \n",
    "    return {\n",
    "        \"rating\": rating,\n",
    "        \"comment\": comment\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test and rate some responses\n",
    "if MODEL_PATH:\n",
    "    # Load dataset examples\n",
    "    if os.path.exists(DATASET_PATH):\n",
    "        with open(DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "            dataset = json.load(f)\n",
    "        \n",
    "        # Select a few random examples\n",
    "        import random\n",
    "        sample_indices = random.sample(range(len(dataset)), 3)\n",
    "        \n",
    "        ratings = []\n",
    "        for idx in sample_indices:\n",
    "            example = dataset[idx]\n",
    "            print(f\"\\nExample {idx}:\")\n",
    "            print(f\"Query: {example['query']}\")\n",
    "            \n",
    "            generated = generate_function_call(\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                query=example['query'],\n",
    "                tools=example['tools'],\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            rating_result = rate_response(generated, example['answers'])\n",
    "            ratings.append({\n",
    "                \"example_idx\": idx,\n",
    "                \"query\": example['query'],\n",
    "                \"rating\": rating_result\n",
    "            })\n",
    "            print(\"\\n\" + \"-\"*50)\n",
    "        \n",
    "        # Custom examples\n",
    "        custom_queries = [\n",
    "            (\"Jaka będzie pogoda w Krakowie przez następne 3 dni?\", weather_tools),\n",
    "            (\"Oblicz wynik wyrażenia (156 + 37) * 2.5\", calculator_tools)\n",
    "        ]\n",
    "        \n",
    "        for query, tools in custom_queries:\n",
    "            print(f\"\\nCustom query: {query}\")\n",
    "            generated = test_custom_query(query, tools)\n",
    "            rating_result = rate_response(generated)\n",
    "            ratings.append({\n",
    "                \"example_idx\": \"custom\",\n",
    "                \"query\": query,\n",
    "                \"rating\": rating_result\n",
    "            })\n",
    "            print(\"\\n\" + \"-\"*50)\n",
    "        \n",
    "        # Save the ratings\n",
    "        import datetime\n",
    "        rating_file = f\"../models/ratings_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(rating_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(ratings, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"Ratings saved to {rating_file}\")\n",
    "    else:\n",
    "        print(f\"Dataset not found at {DATASET_PATH}\")\n",
    "else:\n",
    "    print(\"Please load a model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Example\n",
    "\n",
    "Here's an example of how you could integrate the fine-tuned model into a function calling application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def process_function_call(function_call):\n",
    "    \"\"\"Simulates processing a function call from the model.\"\"\"\n",
    "    if isinstance(function_call, list) and len(function_call) > 0:\n",
    "        # Handle case where model returns a list of function calls\n",
    "        function_call = function_call[0]\n",
    "    \n",
    "    if 'name' not in function_call or 'arguments' not in function_call:\n",
    "        return {\"error\": \"Invalid function call format\"}\n",
    "    \n",
    "    name = function_call['name']\n",
    "    args = function_call['arguments']\n",
    "    \n",
    "    # Simulate function execution\n",
    "    if name == \"get_weather\":\n",
    "        location = args.get('location', 'Unknown')\n",
    "        return {\"result\": f\"Current weather for {location}: 22°C, Partly Cloudy\"}\n",
    "    \n",
    "    elif name == \"get_forecast\":\n",
    "        location = args.get('location', 'Unknown')\n",
    "        days = args.get('days', 1)\n",
    "        return {\"result\": f\"{days}-day forecast for {location}: Sunny, temperatures between 18-25°C\"}\n",
    "    \n",
    "    elif name == \"calculator\":\n",
    "        expression = args.get('expression', '')\n",
    "        try:\n",
    "            # CAUTION: eval is used here for demo purposes only\n",
    "            # In a real application, use a safer method to evaluate expressions\n",
    "            result = eval(expression)\n",
    "            return {\"result\": f\"The result of {expression} is {result}\"}\n",
    "        except:\n",
    "            return {\"error\": f\"Could not evaluate expression: {expression}\"}\n",
    "    \n",
    "    elif name == \"create_calendar_event\":\n",
    "        title = args.get('title', 'Untitled')\n",
    "        start = args.get('start_time', 'Unknown')\n",
    "        end = args.get('end_time', 'Unknown')\n",
    "        return {\"result\": f\"Created calendar event: {title} from {start} to {end}\"}\n",
    "    \n",
    "    else:\n",
    "        return {\"error\": f\"Unknown function: {name}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Example of a complete function calling pipeline\n",
    "def handle_user_query(query, available_tools, model=model, tokenizer=tokenizer):\n",
    "    # Generate function call\n",
    "    function_call = generate_function_call(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        query=query,\n",
    "        tools=available_tools,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    \n",
    "    # Process the function call\n",
    "    result = process_function_call(function_call)\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"function_call\": function_call,\n",
    "        \"result\": result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test the complete pipeline\n",
    "if MODEL_PATH:\n",
    "    # Test queries\n",
    "    test_queries = [\n",
    "        (\"What's the weather in London?\", weather_tools),\n",
    "        (\"Jaka jest pogoda w Warszawie?\", weather_tools),\n",
    "        (\"Calculate 250 * 0.15\", calculator_tools),\n",
    "        (\"Utwórz spotkanie z zespołem na jutro o 14:00 na 2 godziny\", calendar_tools)\n",
    "    ]\n",
    "    \n",
    "    for query, tools in test_queries:\n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        result = handle_user_query(query, tools)\n",
    "        print(\"Function call:\")\n",
    "        print(json.dumps(result[\"function_call\"], indent=2, ensure_ascii=False))\n",
    "        print(\"\\nResult:\")\n",
    "        print(json.dumps(result[\"result\"], indent=2, ensure_ascii=False))\n",
    "        print(\"\\n\" + \"-\"*50)\n",
    "else:\n",
    "    print(\"Please load a model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the fine-tuned PLLuM model for function calling in both Polish and English. The model has been trained to understand queries and generate structured function calls according to the provided tool definitions.\n",
    "\n",
    "Key capabilities demonstrated:\n",
    "1. Loading a fine-tuned PLLuM model\n",
    "2. Generating function calls for both Polish and English queries\n",
    "3. Handling various types of tools and parameters\n",
    "4. Integrating the model into a complete function calling pipeline\n",
    "\n",
    "The fine-tuned model can be integrated into applications that need to parse natural language queries into structured function calls, especially for Polish-language applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
